{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "name": "intro"
   },
   "source": [
    "# Advanced Call Center Analytics with AI_TRANSCRIBE\n",
    "\n",
    "This notebook demonstrates the power of Snowflake's AI_TRANSCRIBE function combined with other Cortex AI functions to extract valuable insights from call center audio files. We will:\n",
    "\n",
    "- **Transcribe** audio files using the new AI_TRANSCRIBE function\n",
    "- **Analyze** call patterns and trends using Cortex Complete\n",
    "- **Extract** key metrics and insights using structured prompts\n",
    "- **Classify** calls by intent, urgency, and satisfaction\n",
    "- **Discover** anomalies and opportunities for improvement\n",
    "- **Generate** actionable recommendations for call center optimization\n",
    "\n",
    "## Key Features of AI_TRANSCRIBE\n",
    "- High-quality transcription using latest AI models\n",
    "- Support for 40+ languages\n",
    "- Maximum file size: 700 MB\n",
    "- Maximum duration: 90 minutes\n",
    "- Supports .mp3 and .wav formats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "language": "python",
    "name": "setup"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import streamlit as st\n",
    "\n",
    "from snowflake.snowpark import Session, DataFrame\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.version import VERSION\n",
    "\n",
    "# Set Variables\n",
    "DATABASE_NAME = \"call_center_analytics_db\"\n",
    "SCHEMA_NAME = \"analytics\"\n",
    "STAGE_NAME = \"audio_files\"\n",
    "ROLE_NAME = \"call_center_analytics_role\"\n",
    "STAGE_PATH_BASE = f'@{DATABASE_NAME}.{SCHEMA_NAME}.{STAGE_NAME}'\n",
    "\n",
    "# Get active session\n",
    "session = get_active_session()\n",
    "session.use_role(ROLE_NAME)\n",
    "session.use_database(DATABASE_NAME)\n",
    "session.use_schema(SCHEMA_NAME)\n",
    "\n",
    "print(f\"‚ùÑÔ∏è Snowflake Session Details:\")\n",
    "print(f\"Role: {session.get_current_role()}\")\n",
    "print(f\"Warehouse: {session.get_current_warehouse()}\")\n",
    "print(f\"Database.Schema: {session.get_fully_qualified_current_schema()}\")\n",
    "print(f\"Stage Name: {STAGE_NAME}\")\n",
    "print(f\"Snowpark Version: {VERSION}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "language": "sql",
    "name": "checkRecordingsInStage",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- List files in the stage\n",
    "LIST {{STAGE_PATH_BASE}}/;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "name": "prepTranscription"
   },
   "source": [
    "## Transcribing Audio Files with AI_TRANSCRIBE\n",
    "\n",
    "Now we'll use AI_TRANSCRIBE to convert our audio files into text. We'll create a table to store FILE objects and process them in batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "language": "sql",
    "name": "createTranscriptionTable",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create table with FILE objects for batch transcription\n",
    "CREATE OR REPLACE TABLE audio_files_for_transcription AS\n",
    "SELECT\n",
    "    RELATIVE_PATH as file_path,\n",
    "    TO_FILE('{{STAGE_PATH_BASE}}', RELATIVE_PATH) as audio_file,\n",
    "    SIZE as file_size_bytes,\n",
    "    LAST_MODIFIED as upload_time,\n",
    "    SPLIT_PART(RELATIVE_PATH, '.', -1) as file_extension,\n",
    "    REPLACE(RELATIVE_PATH, '.mp3', '') as call_id\n",
    "FROM DIRECTORY('{{STAGE_PATH_BASE}}')\n",
    "WHERE RELATIVE_PATH ILIKE '%.mp3' OR RELATIVE_PATH ILIKE '%.wav';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "language": "sql",
    "name": "runTranscription",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Perform AI transcription and save results\n",
    "-- üéôÔ∏è Starting AI transcription process...\n",
    "CREATE OR REPLACE TABLE ai_transcribed_calls AS\n",
    "SELECT\n",
    "    call_id,\n",
    "    file_path,\n",
    "    file_size_bytes,\n",
    "    upload_time,\n",
    "    AI_TRANSCRIBE(audio_file) as transcription_result,\n",
    "    transcription_result:text::STRING as transcript_text,\n",
    "    CURRENT_TIMESTAMP() as transcription_timestamp,\n",
    "    LENGTH(transcription_result:text::STRING) as transcript_length,\n",
    "    ARRAY_SIZE(SPLIT(transcription_result:text::STRING, ' ')) as word_count,\n",
    "    CASE\n",
    "        WHEN transcription_result:text IS NULL THEN 'FAILED'\n",
    "        WHEN LENGTH(transcription_result:text::STRING) < 10 THEN 'SHORT'\n",
    "        ELSE 'SUCCESS'\n",
    "    END as transcription_status\n",
    "FROM audio_files_for_transcription\n",
    "ORDER BY file_size_bytes ASC;  -- Start with smaller files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42831e4d-3d2e-47cb-af7d-b098ead98717",
   "metadata": {
    "language": "python",
    "name": "playSampleAudio"
   },
   "outputs": [],
   "source": [
    "# let's play an example audio file before looking at the transcript\n",
    "# with Snowflake notebooks, you can use Streamlit components directly\n",
    "stage_path = session.sql(f\"\"\"\n",
    "    SELECT '{STAGE_PATH_BASE}/' || RELATIVE_PATH as full_path\n",
    "    FROM DIRECTORY('{STAGE_PATH_BASE}')\n",
    "    WHERE RELATIVE_PATH ILIKE '%.mp3'\n",
    "    ORDER BY LAST_MODIFIED DESC\n",
    "    LIMIT 1\n",
    "\"\"\").collect()[0]['FULL_PATH']\n",
    "\n",
    "try:\n",
    "    # Read the audio file from the internal stage as bytes\n",
    "    with session.file.get_stream(stage_path) as f:\n",
    "        audio_bytes = f.read()\n",
    "\n",
    "    # Use st.audio to play the MP3\n",
    "    # Specify the format as \"audio/mpeg\" for MP3s\n",
    "    st.audio(audio_bytes, format=\"audio/mpeg\", start_time=0)\n",
    "\n",
    "    st.success(f\"Successfully loaded and playing: {stage_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    st.error(f\"Error loading or playing audio: {e}\")\n",
    "    st.info(\"Please ensure the audio file exists on the stage and the stage path is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517aa989-753a-4795-a669-0f7d4c90b6a5",
   "metadata": {
    "language": "sql",
    "name": "viewSampleTranscription",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- View example transcript\n",
    "SELECT\n",
    "    transcript_text\n",
    "FROM ai_transcribed_calls\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "language": "sql",
    "name": "viewTranscriptionSummary",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- View transcription results summary\n",
    "SELECT\n",
    "    transcription_status,\n",
    "    COUNT(*) as call_count,\n",
    "    AVG(word_count) as avg_word_count,\n",
    "    AVG(transcript_length) as avg_transcript_length\n",
    "FROM ai_transcribed_calls\n",
    "GROUP BY transcription_status\n",
    "ORDER BY call_count DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "name": "CortexAnalyseTranscriptions"
   },
   "source": [
    "## Advanced Analytics with Cortex Functions\n",
    "\n",
    "Now we'll use various Cortex AI functions to extract meaningful insights from our transcriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "language": "sql",
    "name": "runCortexAnalysis",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- üîç Performing advanced AI analysis on transcriptions...\n",
    "-- Create comprehensive structured analysis using AI_COMPLETE\n",
    "CREATE OR REPLACE TABLE comprehensive_call_analysis AS\n",
    "SELECT\n",
    "    call_id,\n",
    "    transcript_text,\n",
    "    word_count,\n",
    "\n",
    "    -- Sentiment Analysis\n",
    "    SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) as sentiment_score,\n",
    "    CASE\n",
    "        WHEN SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) > 0.1 THEN 'POSITIVE'\n",
    "        WHEN SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) < -0.1 THEN 'NEGATIVE'\n",
    "        ELSE 'NEUTRAL'\n",
    "    END as sentiment_category,\n",
    "\n",
    "    -- Call Summary\n",
    "    SNOWFLAKE.CORTEX.SUMMARIZE(transcript_text) as call_summary,\n",
    "\n",
    "    -- Advanced structured extraction using AI_COMPLETE with JSON response format\n",
    "    AI_COMPLETE(\n",
    "        model => 'claude-sonnet-4-5',\n",
    "        prompt => 'Analyze this call center conversation and extract structured information. Call transcript: ' || transcript_text,\n",
    "        model_parameters => {'temperature': 0.1, 'max_tokens': 2048},\n",
    "        response_format => {\n",
    "            'type': 'json',\n",
    "            'schema': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'call_type': {'type': 'string', 'enum': ['inbound', 'outbound', 'transfer']},\n",
    "                    'customer_name': {'type': 'string'},\n",
    "                    'agent_name': {'type': 'string'},\n",
    "                    'primary_intent': {'type': 'string', 'enum': ['billing', 'technical_support', 'complaint', 'information', 'sales', 'cancellation', 'other']},\n",
    "                    'urgency_level': {'type': 'string', 'enum': ['low', 'medium', 'high', 'critical']},\n",
    "                    'issue_resolved': {'type': 'string', 'enum': ['yes', 'no', 'partial']},\n",
    "                    'escalation_required': {'type': 'string', 'enum': ['yes', 'no']},\n",
    "                    'customer_satisfaction': {'type': 'string', 'enum': ['satisfied', 'neutral', 'dissatisfied']},\n",
    "                    'call_duration_estimate': {'type': 'string', 'enum': ['short', 'medium', 'long']},\n",
    "                    'key_issues': {'type': 'array', 'items': {'type': 'string'}},\n",
    "                    'action_items': {'type': 'array', 'items': {'type': 'string'}},\n",
    "                    'policy_numbers': {'type': 'array', 'items': {'type': 'string'}},\n",
    "                    'monetary_amounts': {'type': 'array', 'items': {'type': 'string'}},\n",
    "                    'appointment_scheduled': {'type': 'string', 'enum': ['yes', 'no']},\n",
    "                    'callback_requested': {'type': 'string', 'enum': ['yes', 'no']}\n",
    "                },\n",
    "                'required': ['call_type', 'customer_name', 'agent_name', 'primary_intent', 'urgency_level', 'issue_resolved', 'escalation_required', 'customer_satisfaction']\n",
    "            }\n",
    "        }\n",
    "    ) as call_analysis,\n",
    "\n",
    "    -- Quality scoring with AI_COMPLETE\n",
    "    TRY_CAST(\n",
    "        AI_COMPLETE(\n",
    "            model => 'claude-sonnet-4-5',\n",
    "            prompt => 'Rate this call center conversation on a scale of 1-10 for agent performance considering: professionalism, problem-solving, communication clarity, and customer service. Provide only the numeric score (no text). If you cannot determine a score, return null and nothing else: ' || transcript_text,\n",
    "            model_parameters => {'temperature': 0, 'max_tokens': 10}\n",
    "       )::VARCHAR AS NUMBER(3,1)\n",
    "    ) as agent_performance_score,\n",
    "\n",
    "    -- Identify improvement opportunities using AI_COMPLETE\n",
    "    AI_COMPLETE(\n",
    "        model => 'claude-sonnet-4-5',\n",
    "        prompt => 'List 3 specific improvement opportunities for this call center conversation in bullet points: ' || transcript_text,\n",
    "        model_parameters => {'temperature': 0.3, 'max_tokens': 500}\n",
    "    ) as improvement_opportunities,\n",
    "\n",
    "    CURRENT_TIMESTAMP() as analysis_timestamp\n",
    "\n",
    "FROM ai_transcribed_calls\n",
    "WHERE transcription_status = 'SUCCESS'\n",
    "AND transcript_text IS NOT NULL\n",
    "AND LENGTH(transcript_text) > 50;  -- Filter out very short transcripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a960e7a-317a-4c10-a96f-52e373cd4134",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "previewAnalysis",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- preview the data\n",
    "SELECT call_analysis:primary_intent::STRING AS CATEGORY, CALL_SUMMARY, CALL_ANALYSIS, AGENT_PERFORMANCE_SCORE FROM comprehensive_call_analysis;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "language": "sql",
    "name": "extractAnalysisJson",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Extract JSON fields for easier querying\n",
    "ALTER TABLE comprehensive_call_analysis\n",
    "ADD COLUMN\n",
    "    call_type STRING,\n",
    "    customer_name STRING,\n",
    "    agent_name STRING,\n",
    "    primary_intent STRING,\n",
    "    urgency_level STRING,\n",
    "    issue_resolved STRING,\n",
    "    escalation_required STRING,\n",
    "    customer_satisfaction STRING;\n",
    "\n",
    "\n",
    "UPDATE comprehensive_call_analysis\n",
    "SET\n",
    "    call_type = call_analysis:call_type::STRING,\n",
    "    customer_name = call_analysis:customer_name::STRING,\n",
    "    agent_name = call_analysis:agent_name::STRING,\n",
    "    primary_intent = call_analysis:primary_intent::STRING,\n",
    "    urgency_level = call_analysis:urgency_level::STRING,\n",
    "    issue_resolved = call_analysis:issue_resolved::STRING,\n",
    "    escalation_required = call_analysis:escalation_required::STRING,\n",
    "    customer_satisfaction = call_analysis:customer_satisfaction::STRING;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "language": "sql",
    "name": "summariseAnalysis",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- üìä Analysis Summary\n",
    "SELECT\n",
    "    COUNT(*) as total_calls,\n",
    "    ROUND(AVG(sentiment_score), 3) as avg_sentiment,\n",
    "    ROUND(AVG(agent_performance_score), 1) as avg_agent_score,\n",
    "    COUNT(DISTINCT agent_name) as unique_agents,\n",
    "    COUNT(DISTINCT primary_intent) as unique_call_types\n",
    "FROM comprehensive_call_analysis;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "name": "Insights"
   },
   "source": [
    "## Discovering Key Insights and Patterns\n",
    "\n",
    "Let's analyze the data to uncover interesting patterns and actionable insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000015",
   "metadata": {
    "language": "sql",
    "name": "analyseAgentPerformance",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- üèÜ Agent Performance Analysis\n",
    "SELECT\n",
    "    agent_name,\n",
    "    COUNT(*) as total_calls,\n",
    "    ROUND(AVG(sentiment_score), 3) as avg_sentiment,\n",
    "    ROUND(AVG(agent_performance_score), 1) as avg_performance_score,\n",
    "\n",
    "    -- Resolution effectiveness\n",
    "    SUM(CASE WHEN issue_resolved = 'yes' THEN 1 ELSE 0 END) as resolved_calls,\n",
    "    ROUND(SUM(CASE WHEN issue_resolved = 'yes' THEN 1 ELSE 0 END) / COUNT(*) * 100, 1) as resolution_rate,\n",
    "\n",
    "    -- Customer satisfaction\n",
    "    SUM(CASE WHEN customer_satisfaction = 'satisfied' THEN 1 ELSE 0 END) as satisfied_customers,\n",
    "    ROUND(SUM(CASE WHEN customer_satisfaction = 'satisfied' THEN 1 ELSE 0 END) / COUNT(*) * 100, 1) as satisfaction_rate,\n",
    "\n",
    "    -- Escalation patterns\n",
    "    SUM(CASE WHEN escalation_required = 'yes' THEN 1 ELSE 0 END) as escalations,\n",
    "    ROUND(SUM(CASE WHEN escalation_required = 'yes' THEN 1 ELSE 0 END) / COUNT(*) * 100, 1) as escalation_rate\n",
    "\n",
    "FROM comprehensive_call_analysis\n",
    "WHERE agent_name != 'Not Available' AND agent_name IS NOT NULL\n",
    "GROUP BY agent_name\n",
    "ORDER BY avg_performance_score DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91268fe-d919-4ed6-8787-1828f1ada0e7",
   "metadata": {
    "language": "sql",
    "name": "analyseCallPatterns",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- üìä Call Pattern Analysis\n",
    "WITH call_patterns AS (\n",
    "    SELECT\n",
    "        primary_intent,\n",
    "        urgency_level,\n",
    "        COUNT(*) as call_count,\n",
    "        ROUND(AVG(sentiment_score), 3) as avg_sentiment,\n",
    "        ROUND(AVG(agent_performance_score), 1) as avg_agent_score,\n",
    "\n",
    "        -- Resolution patterns\n",
    "        ROUND(SUM(CASE WHEN issue_resolved = 'yes' THEN 1 ELSE 0 END) / COUNT(*) * 100, 1) as resolution_rate,\n",
    "\n",
    "        -- Satisfaction patterns\n",
    "        ROUND(SUM(CASE WHEN customer_satisfaction = 'satisfied' THEN 1 ELSE 0 END) / COUNT(*) * 100, 1) as satisfaction_rate,\n",
    "\n",
    "        -- Escalation patterns\n",
    "        ROUND(SUM(CASE WHEN escalation_required = 'yes' THEN 1 ELSE 0 END) / COUNT(*) * 100, 1) as escalation_rate\n",
    "\n",
    "    FROM comprehensive_call_analysis\n",
    "    WHERE primary_intent IS NOT NULL AND primary_intent != 'Not Available'\n",
    "    GROUP BY primary_intent, urgency_level\n",
    ")\n",
    "SELECT\n",
    "    primary_intent,\n",
    "    urgency_level,\n",
    "    call_count,\n",
    "    avg_sentiment,\n",
    "    avg_agent_score,\n",
    "    resolution_rate || '%' as resolution_rate_pct,\n",
    "    satisfaction_rate || '%' as satisfaction_rate_pct,\n",
    "    escalation_rate || '%' as escalation_rate_pct,\n",
    "\n",
    "    -- Performance flags\n",
    "    CASE\n",
    "        WHEN resolution_rate < 70 THEN '‚ö†Ô∏è Low Resolution'\n",
    "        WHEN satisfaction_rate < 60 THEN '‚ö†Ô∏è Low Satisfaction'\n",
    "        WHEN escalation_rate > 30 THEN '‚ö†Ô∏è High Escalation'\n",
    "        ELSE '‚úÖ Good Performance'\n",
    "    END as performance_flag\n",
    "\n",
    "FROM call_patterns\n",
    "ORDER BY call_count DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000016",
   "metadata": {
    "collapsed": false,
    "name": "conclusion"
   },
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "This notebook has demonstrated the powerful capabilities of AI_TRANSCRIBE combined with Snowflake's Cortex AI functions to:\n",
    "\n",
    "‚úÖ **Automatically transcribe** call center audio files with high accuracy  \n",
    "‚úÖ **Extract structured insights** from unstructured conversation data  \n",
    "‚úÖ **Identify performance patterns** and improvement opportunities  \n",
    "‚úÖ **Detect anomalies** and quality issues automatically  \n",
    "‚úÖ **Generate actionable recommendations** using AI analysis  \n",
    "‚úÖ **Create comprehensive reports** for management decision-making  \n",
    "\n",
    "### Key Advantages of AI_TRANSCRIBE:\n",
    "- **No infrastructure management** - serverless transcription\n",
    "- **Multi-language support** - 40+ languages supported\n",
    "- **High accuracy** - latest AI models for transcription\n",
    "- **Scalable processing** - handle large volumes of audio files\n",
    "- **Integrated analytics** - seamless combination with other Cortex functions\n",
    "\n",
    "### Recommended Next Steps:\n",
    "1. **View Streamlit application** for natural language analysis using Cortex Agents\n",
    "1. **Upload your own recordings** on the stage to apply this to your use case\n",
    "2. **Set up automated pipelines** for real-time call analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "dan.chaffelson@snowflake.com",
   "authorId": "75544643758",
   "authorName": "DCHAFFELSON",
   "lastEditTime": 1759330214395,
   "notebookId": "ftoqnsjaul4giips2h4w",
   "sessionId": "c67526ee-7873-43e1-befd-ccdd990edea0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
